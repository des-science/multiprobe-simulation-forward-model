{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28eb0718-fdb2-4f65-8551-0bb73d4ab00b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45056515-e14a-4201-a4fa-a119acc63bed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices(device_type=\"GPU\")[0], True)\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from msfm.utils import tfrecords, files, parameters, cross_statistics\n",
    "from msfm.fiducial_pipeline import FiducialPipeline\n",
    "from msfm.grid_pipeline import GridPipeline\n",
    "from msfm.utils.input_output import read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da3cc739-78ad-4f07-b58e-2179565e52ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with_lensing = True\n",
    "with_clustering = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e484789a-7a36-40df-8df7-cf7edf23abc7",
   "metadata": {},
   "source": [
    "# grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6117efc-5e3e-4457-8d80-42134cb5bef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tfr_pattern = \"/pscratch/sd/a/athomsen/v11desy3/v10/debug/linear_bias/tfrecords/grid/DESy3_grid_dmb_0000.tfrecord\"\n",
    "# tfr_pattern = \"/pscratch/sd/a/athomsen/v11desy3/v10/linear_bias/tfrecords/grid/DESy3_grid_dmb_0000.tfrecord\"\n",
    "\n",
    "tfr_pattern = \"/pscratch/sd/a/athomsen/v11desy3/v10/debug/linear_bias/tfrecords/grid/DESy3power_law_grid_dmb_0000.tfrecord\"\n",
    "# tfr_pattern = \"/pscratch/sd/a/athomsen/v11desy3/v10/linear_bias/tfrecords/grid/DESy3per_bin_grid_dmb_0000.tfrecord\"\n",
    "\n",
    "# conf = \"/global/homes/a/athomsen/multiprobe-simulation-forward-model/configs/v10/linear_bias_debug.yaml\"\n",
    "conf = \"/global/homes/a/athomsen/multiprobe-simulation-forward-model/configs/v10/linear_bias.yaml\"\n",
    "conf = files.load_config(conf)\n",
    "\n",
    "params = [\"Om\", \"s8\", \"Ob\", \"H0\", \"ns\", \"w0\", \"Aia\", \"n_Aia\", \"bg\", \"n_bg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a92b689-d6cd-4c89-896e-d143d1cc04f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-01 07:11:22     files.py INF   Loaded the pixel file /global/u2/a/athomsen/multiprobe-simulation-forward-model/data/DESY3_pixels_v11_fiducial_512.h5 \n",
      "24-10-01 07:11:22     files.py INF   Loaded the pixel file /global/u2/a/athomsen/multiprobe-simulation-forward-model/data/DESY3_pixels_v11_fiducial_512.h5 \n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridPipeline(\n",
    "    conf=conf,\n",
    "    params=params,\n",
    "    with_lensing=with_lensing,\n",
    "    with_clustering=with_clustering,\n",
    "    with_padding=True,\n",
    "    apply_norm=False,\n",
    "    return_maps=True,\n",
    ")\n",
    "\n",
    "data_vec_pix = grid_pipe.data_vec_pix\n",
    "n_side = conf[\"analysis\"][\"n_side\"]\n",
    "n_pix = hp.nside2npix(n_side)\n",
    "n_z = grid_pipe.n_z_metacal + grid_pipe.n_z_maglim\n",
    "n_z_metacal = grid_pipe.n_z_metacal\n",
    "n_noise = conf[\"analysis\"][\"grid\"][\"n_noise_per_example\"]\n",
    "# n_noise = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69c9da8-bc01-4514-8167-a79d2d754ce6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_perms_per_cosmo = conf[\"analysis\"][\"grid\"][\"n_perms_per_cosmo\"]\n",
    "n_patches = conf[\"analysis\"][\"n_patches\"]\n",
    "n_signal = n_perms_per_cosmo * n_patches\n",
    "\n",
    "batch_size = 1\n",
    "n_batches = n_signal * n_noise // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb87f59-4306-443b-9c68-7cb781406135",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-01 07:11:24 grid_pipelin INF   n_workers is not set, using tf.data.AUTOTUNE. This might produce unexpected RAM usage. \n",
      "24-10-01 07:11:24 grid_pipelin INF   drop_remainder is not set, using drop_remainder = False \n",
      "24-10-01 07:11:24 grid_pipelin INF   Including noise_indices = [0] \n",
      "24-10-01 07:11:24 grid_pipelin INF   Interleaving with n_readers = 1 \n",
      "dict_keys(['cosmo', 'i_sobol', 'i_example', 'kg', 'dg', 'cl'])\n",
      "24-10-01 07:11:25 grid_pipelin INF   Batching into 1 elements locally \n",
      "\u001b[1m\u001b[93m24-10-01 07:11:26 grid_pipelin WAR   Tracing _augmentations \u001b[0m\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f2d5b446d60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7f2d5b446d60>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "24-10-01 07:11:27 grid_pipelin INF   Running on the data_vectors.keys() = dict_keys(['cosmo', 'i_sobol', 'i_example', 'kg', 'dg', 'cl', 'i_noise']) \n",
      "24-10-01 07:11:27 grid_pipelin INF   Successfully generated the grid validation set with element_spec (TensorSpec(shape=(None, 460800, 8), dtype=tf.float32, name=None), TensorSpec(shape=(None, 1536, 36), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None), (TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))) \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:05, 14.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grid_dset = grid_pipe.get_dset(\n",
    "    tfr_pattern=\"/pscratch/sd/a/athomsen/v11desy3/v10/linear_bias/tfrecords/grid/DESy3_grid_dmb_0000.tfrecord\",\n",
    "    noise_indices=1,\n",
    "    local_batch_size=1,\n",
    "    n_readers=1,\n",
    "    n_prefetch=0,\n",
    "    is_eval=True,\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for dv, cl, cosmo, index in tqdm(grid_dset):\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28896191-b875-4b4c-bc98-56f3250c8d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24-10-01 07:11:33 grid_pipelin INF   n_workers is not set, using tf.data.AUTOTUNE. This might produce unexpected RAM usage. \n",
      "24-10-01 07:11:33 grid_pipelin INF   drop_remainder is not set, using drop_remainder = False \n",
      "24-10-01 07:11:33 grid_pipelin INF   Including noise_indices = [0, 1, 2, 3, 4] \n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: /pscratch/sd/a/athomsen/v11desy3/v10/debug/linear_bias/tfrecords/grid/DESy3power_law_grid_dmb_0000.tfrecord'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grid_dset \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtfr_pattern\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfr_pattern\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnoise_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_readers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_prefetch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dv, cl, cosmo, index \u001b[38;5;129;01min\u001b[39;00m grid_dset:\n",
      "File \u001b[0;32m/global/u2/a/athomsen/multiprobe-simulation-forward-model/msfm/grid_pipeline.py:188\u001b[0m, in \u001b[0;36mGridPipeline.get_dset\u001b[0;34m(self, tfr_pattern, local_batch_size, noise_indices, n_readers, n_workers, n_prefetch, file_name_shuffle_buffer, examples_shuffle_buffer, is_eval, drop_remainder, eval_seed, file_name_shuffle_seed, examples_shuffle_seed, input_context)\u001b[0m\n\u001b[1;32m    185\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncluding noise_indices = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(noise_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# get the file names and dataset them\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m dset \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtfr_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_eval\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_name_shuffle_seed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# shard for distributed evaluation\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# NOTE that for the builtin MirroredStrategy, input_context.num_input_pipelines = 1 and\u001b[39;00m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;66;03m# input_context.input_pipeline_id = 0, indicating that no sharding happens\u001b[39;00m\n\u001b[1;32m    194\u001b[0m     \u001b[38;5;66;03m# NOTE My HorovodStrategy is written to be compatible with this\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \n\u001b[1;32m    196\u001b[0m     \u001b[38;5;66;03m# Taken from https://www.tensorflow.org/tutorials/distribute/input#usage_2\u001b[39;00m\n",
      "File \u001b[0;32m/global/common/software/des/athomsen/dlss/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py:1379\u001b[0m, in \u001b[0;36mDatasetV2.list_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1372\u001b[0m condition \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mgreater(array_ops\u001b[38;5;241m.\u001b[39mshape(matching_files)[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   1373\u001b[0m                              name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch_not_empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1375\u001b[0m message \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39madd(\n\u001b[1;32m   1376\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo files matched pattern: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1377\u001b[0m     string_ops\u001b[38;5;241m.\u001b[39mreduce_join(file_pattern, separator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1379\u001b[0m assert_not_empty \u001b[38;5;241m=\u001b[39m \u001b[43mcontrol_flow_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAssert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massert_not_empty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcontrol_dependencies([assert_not_empty]):\n\u001b[1;32m   1382\u001b[0m   matching_files \u001b[38;5;241m=\u001b[39m array_ops\u001b[38;5;241m.\u001b[39midentity(matching_files)\n",
      "File \u001b[0;32m/global/common/software/des/athomsen/dlss/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/global/common/software/des/athomsen/dlss/lib/python3.9/site-packages/tensorflow/python/ops/control_flow_ops.py:155\u001b[0m, in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    153\u001b[0m     xs \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_n_to_tensor(data)\n\u001b[1;32m    154\u001b[0m     data_str \u001b[38;5;241m=\u001b[39m [_summarize_eager(x, summarize) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m xs]\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError(\n\u001b[1;32m    156\u001b[0m         node_def\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    157\u001b[0m         op\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to be true. Summarized data: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    159\u001b[0m         (condition, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data_str)))\n\u001b[1;32m    160\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssert\u001b[39m\u001b[38;5;124m\"\u001b[39m, [condition, data]) \u001b[38;5;28;01mas\u001b[39;00m name:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: /pscratch/sd/a/athomsen/v11desy3/v10/debug/linear_bias/tfrecords/grid/DESy3power_law_grid_dmb_0000.tfrecord'"
     ]
    }
   ],
   "source": [
    "grid_dset = grid_pipe.get_dset(\n",
    "    tfr_pattern=tfr_pattern,\n",
    "    noise_indices=n_noise,\n",
    "    local_batch_size=batch_size,\n",
    "    n_readers=1,\n",
    "    n_prefetch=0,\n",
    "    is_eval=True,\n",
    ")\n",
    "\n",
    "i = 0\n",
    "for dv, cl, cosmo, index in grid_dset:\n",
    "    print(index[1])\n",
    "    i += 1\n",
    "    \n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e452ea4f-fa3b-4b31-9be1-88e990a08cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# grid_dset = grid_pipe.get_dset(\n",
    "#     tfr_pattern=tfr_pattern,\n",
    "#     noise_indices=n_noise,\n",
    "#     local_batch_size=batch_size,\n",
    "#     n_readers=1,\n",
    "#     n_prefetch=0,\n",
    "#     is_eval=False,\n",
    "# )\n",
    "\n",
    "# for dv, cl, cosmo, index in tqdm(grid_dset.take(n_batches), total=n_batches):\n",
    "#     print(index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0ce005-1139-464e-b87c-a3d62a44b39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlss",
   "language": "python",
   "name": "dlss"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
