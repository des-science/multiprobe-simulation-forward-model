{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import healpy as hp\n",
    "\n",
    "from deepsphere import HealpyGCNN\n",
    "\n",
    "from msfm.models.base_model import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 10:49:28.509629: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-14 10:49:28.509765: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "tf.print(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_checkpoint = \"./base_checkpoint\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# checkpointing tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup a base model to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, None, 4)           20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:49:28 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "[<tf.Variable 'dense/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[ 0.21377103,  0.47058317, -0.2539105 ,  0.52947545],\n",
      "       [ 0.25066075, -0.28327873,  0.31893608, -0.5901518 ],\n",
      "       [ 0.42085022,  0.4011252 , -0.12141883,  0.42287856],\n",
      "       [-0.8038719 ,  0.7253791 , -0.5630019 ,  0.32778645]],\n",
      "      dtype=float32)>, <tf.Variable 'dense/bias:0' shape=(4,) dtype=float32, numpy=array([ 0.00099983, -0.00099956,  0.00099987,  0.00099966], dtype=float32)>] \n",
      "\n",
      "\n",
      "\n",
      "<tf.Variable 'GlobalStep:0' shape=() dtype=int64, numpy=20> \n",
      "\n",
      "\n",
      "\n",
      "[<tf.Variable 'Adam/iter:0' shape=() dtype=int64, numpy=10>, <tf.Variable 'Adam/dense/kernel/m:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[-0.6079423 ,  0.12873407, -0.9282435 , -0.24227647],\n",
      "       [-0.91638315,  0.19619364, -1.1522634 , -0.76187587],\n",
      "       [-0.7445847 ,  0.42337415, -1.0513955 , -0.45898548],\n",
      "       [-1.2784797 ,  0.62758577, -1.5155648 , -0.41640064]],\n",
      "      dtype=float32)>, <tf.Variable 'Adam/dense/bias/m:0' shape=(4,) dtype=float32, numpy=array([-1.8251635 ,  0.71079767, -2.3743324 , -0.90376675], dtype=float32)>, <tf.Variable 'Adam/dense/kernel/v:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[0.00868289, 0.000391  , 0.02023457, 0.00138136],\n",
      "       [0.01972664, 0.00090769, 0.03118245, 0.01363825],\n",
      "       [0.01302351, 0.00421397, 0.02595976, 0.00495198],\n",
      "       [0.03838662, 0.00925752, 0.05393711, 0.00407876]], dtype=float32)>, <tf.Variable 'Adam/dense/bias/v:0' shape=(4,) dtype=float32, numpy=array([0.07824291, 0.01188368, 0.1323835 , 0.01920239], dtype=float32)>] \n",
      "\n",
      "\n",
      "\n",
      "23-02-14 10:49:29 base_model.p INF   Successfully saved the model to ./base_checkpoint \n"
     ]
    }
   ],
   "source": [
    "network = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((None, 4)),\n",
    "    tf.keras.layers.Dense(4)\n",
    "    ])\n",
    "\n",
    "model = BaseModel(network, (None, 2), dir_checkpoint=dir_checkpoint)\n",
    "model.train_step.assign(10)\n",
    "X = tf.random.uniform((10, 4), seed=1)\n",
    "y = tf.random.uniform((10, 4), seed=2)\n",
    "for _ in range(10):\n",
    "    model.base_train_step(X, tf.keras.losses.mean_squared_error, y)\n",
    "\n",
    "print(model.network.weights, \"\\n\\n\\n\")\n",
    "print(model.train_step, \"\\n\\n\\n\")\n",
    "print(model.optimizer.variables(), \"\\n\\n\\n\")\n",
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load that model\n",
    "the variables should be identical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, None, 4)           20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "23-02-14 10:49:29 base_model.p INF   Network successfully restored from checkpoint ./base_checkpoint/ckpt-1. \n",
      "[<tf.Variable 'dense_1/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[ 0.21377103,  0.47058317, -0.2539105 ,  0.52947545],\n",
      "       [ 0.25066075, -0.28327873,  0.31893608, -0.5901518 ],\n",
      "       [ 0.42085022,  0.4011252 , -0.12141883,  0.42287856],\n",
      "       [-0.8038719 ,  0.7253791 , -0.5630019 ,  0.32778645]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/bias:0' shape=(4,) dtype=float32, numpy=array([ 0.00099983, -0.00099956,  0.00099987,  0.00099966], dtype=float32)>] \n",
      "\n",
      "\n",
      "\n",
      "<tf.Variable 'GlobalStep:0' shape=() dtype=int64, numpy=20> \n",
      "\n",
      "\n",
      "\n",
      "[<tf.Variable 'dense_1/kernel/m:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[-0.6079423 ,  0.12873407, -0.9282435 , -0.24227647],\n",
      "       [-0.91638315,  0.19619364, -1.1522634 , -0.76187587],\n",
      "       [-0.7445847 ,  0.42337415, -1.0513955 , -0.45898548],\n",
      "       [-1.2784797 ,  0.62758577, -1.5155648 , -0.41640064]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_1/kernel/v:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[0.00868289, 0.000391  , 0.02023457, 0.00138136],\n",
      "       [0.01972664, 0.00090769, 0.03118245, 0.01363825],\n",
      "       [0.01302351, 0.00421397, 0.02595976, 0.00495198],\n",
      "       [0.03838662, 0.00925752, 0.05393711, 0.00407876]], dtype=float32)>, <tf.Variable 'dense_1/bias/m:0' shape=(4,) dtype=float32, numpy=array([-1.8251635 ,  0.71079767, -2.3743324 , -0.90376675], dtype=float32)>, <tf.Variable 'dense_1/bias/v:0' shape=(4,) dtype=float32, numpy=array([0.07824291, 0.01188368, 0.1323835 , 0.01920239], dtype=float32)>] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((None, 4)),\n",
    "    tf.keras.layers.Dense(4)\n",
    "    ])\n",
    "\n",
    "model_1 = BaseModel(network, (None, 2), dir_checkpoint=dir_checkpoint, restore_from_checkpoint=True)\n",
    "print(model_1.network.weights, \"\\n\\n\\n\")\n",
    "print(model_1.train_step, \"\\n\\n\\n\")\n",
    "print(model_1.optimizer.variables(), \"\\n\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize from scratch\n",
    "the variables should be different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_2 (Dense)             (None, None, 4)           20        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "23-02-14 10:49:29 base_model.p WAR   The model can not be saved when it is initialized from scratch with a non-empty checkpoint directory \n",
      "[<tf.Variable 'dense_2/kernel:0' shape=(4, 4) dtype=float32, numpy=\n",
      "array([[-0.7698748 ,  0.48782164,  0.10950154, -0.2850235 ],\n",
      "       [-0.01792341, -0.3727775 , -0.83747566,  0.6467523 ],\n",
      "       [-0.44493857,  0.40461046, -0.29707783,  0.2723872 ],\n",
      "       [-0.67028874, -0.05776989, -0.62274957,  0.07873529]],\n",
      "      dtype=float32)>, <tf.Variable 'dense_2/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>] \n",
      "\n",
      "\n",
      "\n",
      "<tf.Variable 'GlobalStep:0' shape=() dtype=int64, numpy=0> \n",
      "\n",
      "\n",
      "\n",
      "[] \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "network = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((None, 4)),\n",
    "    tf.keras.layers.Dense(4)\n",
    "    ])\n",
    "\n",
    "model_2 = BaseModel(network, (None, 2), dir_checkpoint=dir_checkpoint, restore_from_checkpoint=False)\n",
    "print(model_2.network.weights, \"\\n\\n\\n\")\n",
    "print(model_2.train_step, \"\\n\\n\\n\")\n",
    "print(model_2.optimizer.variables(), \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conflict handling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to save the model creates another checkpoint, since it's a continuation of the original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-14 10:49:29 base_model.p INF   Successfully saved the model to ./base_checkpoint \n"
     ]
    }
   ],
   "source": [
    "model_1.save_model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to save the model results in an error, since it was initialized from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The specified checkpoint directory ./base_checkpoint is not empty, can not save a model initialized from scratch there.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_2\u001b[39m.\u001b[39;49msave_model()\n",
      "File \u001b[0;32m~/git/multiprobe-simulation-forward-model/msfm/models/base_model.py:141\u001b[0m, in \u001b[0;36mBaseModel.save_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrestore_from_checkpoint \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_manager\u001b[39m.\u001b[39mcheckpoints) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\n\u001b[1;32m    142\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe specified checkpoint directory \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdir_checkpoint\u001b[39m}\u001b[39;00m\u001b[39m is not empty, can not save a model\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    143\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m initialized from scratch there.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m         )\n\u001b[1;32m    145\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheckpoint_manager\u001b[39m.\u001b[39msave()\n",
      "\u001b[0;31mException\u001b[0m: The specified checkpoint directory ./base_checkpoint is not empty, can not save a model initialized from scratch there."
     ]
    }
   ],
   "source": [
    "model_2.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "des",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a491ce236b7462c2d10c5eba11df8cbf31130dea204ba4d12248d0f0c801e5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
