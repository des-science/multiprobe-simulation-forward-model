{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import healpy as hp\n",
    "\n",
    "from deepsphere import HealpyGCNN\n",
    "\n",
    "from msfm.models.base_model import BaseModel\n",
    "from msfm.models.delta_model import DeltaLossModel\n",
    "from msfm.models.nets import small_resnet_partial\n",
    "from msfm.utils.fiducial_pipeline import get_fiducial_dset\n",
    "from msfm.utils.input_output import read_yaml\n",
    "from msfm.utils import survey\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-14 10:20:18    survey.py INF   Loaded pixel file \n",
      "3 ['fiducial' 'delta_Om_m' 'delta_Om_p']\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "conf_dir = \"../../configs/config.yaml\"\n",
    "repo_dir = \"../..\"\n",
    "conf = read_yaml(conf_dir)\n",
    "data_vec_pix, _, _, _, _ = survey.load_pixel_file(conf, repo_dir)\n",
    "\n",
    "n_side = conf[\"analysis\"][\"n_side\"]\n",
    "n_pix = len(data_vec_pix)\n",
    "n_params = 1 #  Om\n",
    "pert_indices = np.array([0,7,8])\n",
    "pert_labels = np.array(conf[\"analysis\"][\"fiducial\"][\"perturbations\"][\"labels\"])[pert_indices]\n",
    "pert_off_set = [0.01]\n",
    "print(len(pert_labels), pert_labels)\n",
    "n_z_bins = 4\n",
    "\n",
    "# dataset\n",
    "tfr_pattern = \"/Users/arne/data/DESY3/tfrecords/v2/DESy3_fiducial_000.tfrecord\"\n",
    "# tfr_pattern = \"/cluster/scratch/athomsen/CosmoGrid/v2/fiducial/DESy3_fiducial_???.tfrecord\"\n",
    "batch_size = 4\n",
    "examples_shuffle_buffer = 10\n",
    "n_readers = 1\n",
    "n_prefetch = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up the fiducial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-14 10:20:18 fiducial_pip INF   Starting to generate the fiducial training set for i_noise = 0 \n",
      "23-02-14 10:20:18    survey.py INF   Loaded pixel file \n",
      "23-02-14 10:20:18    survey.py INF   Loaded pixel file \n",
      "Metal device set to: Apple M1 Max\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 10:20:18.445582: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-02-14 10:20:18.445774: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method PercentStyle._format of <logging.PercentStyle object at 0x2bcfb3a30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute '_fields'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method PercentStyle._format of <logging.PercentStyle object at 0x2bcfb3a30>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'NoneType' object has no attribute '_fields'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "23-02-14 10:20:18 tfrecords.py WAR   Tracing parse_inverse_fiducial \n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x10601c8e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x10601c8e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "23-02-14 10:20:19 fiducial_pip WAR   Tracing dset_remove_mean \n",
      "23-02-14 10:20:19 fiducial_pip WAR   Tracing dset_add_bias \n",
      "23-02-14 10:20:19 fiducial_pip WAR   Tracing dset_add_noise \n",
      "23-02-14 10:20:19 fiducial_pip WAR   Tracing dset_concat_perts \n",
      "23-02-14 10:20:19 fiducial_pip INF   Successfully generated the fiducial training set with element_spec\n",
      "(TensorSpec(shape=(12, 463872, 4), dtype=tf.float32, name=None), (TensorSpec(shape=(4,), dtype=tf.int64, name=None), TensorSpec(shape=(4,), dtype=tf.int32, name=None)))\n",
      "for i_noise = 0 \n"
     ]
    }
   ],
   "source": [
    "fiducial_dset = get_fiducial_dset(\n",
    "    conf,\n",
    "    repo_dir,\n",
    "    tfr_pattern,\n",
    "    pert_labels,\n",
    "    i_noise=0,\n",
    "    batch_size=batch_size,\n",
    "    examples_shuffle_buffer=examples_shuffle_buffer,\n",
    "    n_readers=n_readers,\n",
    "    n_prefetch=n_prefetch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-14 10:20:19 delta_model. INF   Initializing DeltaLossModel with a HealpyGCNN model \n",
      "WARNING: This network assumes that everything concerning healpy is in NEST ordering...\n",
      "Detected a reduction factor of 32.0, the input with nside 512 will be transformed to 16 during a forward pass. Checking for consistency with indices...\n",
      "indices seem consistent...\n",
      "Model: \"healpy_gcnn_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " healpy_pseudo_conv (HealpyP  (None, 115968, 32)       544       \n",
      " seudoConv)                                                      \n",
      "                                                                 \n",
      " healpy_pseudo_conv_1 (Healp  (None, 28992, 64)        8256      \n",
      " yPseudoConv)                                                    \n",
      "                                                                 \n",
      " healpy_pseudo_conv_2 (Healp  (None, 7248, 128)        32896     \n",
      " yPseudoConv)                                                    \n",
      "                                                                 \n",
      " chebyshev (Chebyshev)       (None, 7248, 256)         163840    \n",
      "                                                                 \n",
      " layer_normalization (LayerN  (None, 7248, 256)        512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " healpy_pseudo_conv_3 (Healp  (None, 1812, 256)        262400    \n",
      " yPseudoConv)                                                    \n",
      "                                                                 \n",
      " chebyshev_1 (Chebyshev)     (None, 1812, 256)         327680    \n",
      "                                                                 \n",
      " layer_normalization_1 (Laye  (None, 1812, 256)        512       \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " healpy_pseudo_conv_4 (Healp  (None, 453, 256)         262400    \n",
      " yPseudoConv)                                                    \n",
      "                                                                 \n",
      " gcnn__residual_layer (GCNN_  (None, 453, 256)         656896    \n",
      " ResidualLayer)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115968)            0         \n",
      "                                                                 \n",
      " layer_normalization_2 (Laye  (None, 115968)           231936    \n",
      " rNormalization)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 115969    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,063,841\n",
      "Trainable params: 2,063,841\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "23-02-14 10:20:20 base_model.p INF   Network successfully restored from checkpoint ./checkpoint/ckpt-1. \n"
     ]
    }
   ],
   "source": [
    "network = small_resnet_partial.get_network(n_params)\n",
    "delta_model = DeltaLossModel(\n",
    "    network,\n",
    "    n_side,\n",
    "    data_vec_pix,\n",
    "    n_neighbors=8,\n",
    "    input_shape=(None, n_pix, n_z_bins),\n",
    "    dir_summary=\"./summary\",\n",
    "    dir_checkpoint=\"./checkpoint\",\n",
    "    restore_checkpoint=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up the delta loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_model.setup_delta_loss_step(\n",
    "    n_params=n_params, n_same=batch_size, off_sets=pert_off_set, n_channels=n_z_bins, n_output=n_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 10:20:20.821290: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23-02-14 10:20:22 delta_model. WAR   Tracing delta_train_step \n",
      "23-02-14 10:20:22 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n",
      "23-02-14 10:20:24 delta_model. WAR   Tracing delta_train_step \n",
      "23-02-14 10:20:24 base_model.p WAR   Performing a base_train_step in python instead of a tf.function \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 10:20:25.049510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "for data_vec, index in fiducial_dset.take(100):\n",
    "    delta_model.delta_train_step(data_vec)\n",
    "\n",
    "# delta_model.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "des",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4a491ce236b7462c2d10c5eba11df8cbf31130dea204ba4d12248d0f0c801e5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
